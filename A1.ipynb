{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yujun-Liang/UTS_ML2019_ID12786277/blob/master/A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoBR6H0a9Hnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiRHrygo9Iwj",
        "colab_type": "text"
      },
      "source": [
        "#Introduction\n",
        "\n",
        "Although humans can recognize the known face, identifying faces in the database that contains a large number of unknown faces has become a problem. Face recognition refers to the technology that picking up a specific face from photo or video in the database by comparing selected facial features. As the increasing application of human face recognition, serval challengers come out, the main challenger of face recognition including variations in illumination, head rotation, facial expression and aging(Carrera 2010).\n",
        "\n",
        "This paper is base on the report ‘Eigenfaces vs. Fisherfaces: Recognition Using specific Linear Projection’. Which addressing the variations in illumination and expressions problem in face-recognizing challenger. This paper will briefly describe the context of the report, evaluates the report in innovation, technical quality, serval X-factor and presentation aspects. \n",
        "\n",
        "#Content\n",
        "\n",
        "Many methods can be used in face recognition that performs differently efficiency, requirements and processing time. In this report, four methods: Correlation, Eigenfaces, Linear Subspaces, and Fisherfaces are being described, compared in three experiments. The final results indicate the “fisherface\" method has the relatively high accuracy than the others under varying illumination.\n",
        "\n",
        "The first method is neighbor classifier, as known as the k-nearest neighbor algorithm. In genal, this method has a simple rule but it required high computational cost when dealing whit large training set. In face recognition, the method classifies the image in the test set according to the assigned label of the nearest point in the learning set. After the preprocessing, all images are normalized to zero mean and unit variance, the image with closest distances can be detected as most correlates result. The report points out the weakness of k-nearest when dealing with varying lighting conditions, the same photo with different lighting condition may lead to the corresponding points that used to compare in data set are not being clustered, resulting in increasing error rate. Besides, the k-nearest neighbor is kind of method that stores the data in classifier until the calculation process begin, in this case,  human face data requires large amount of storage, this becomes anther main issue in Correlation method.\n",
        "\n",
        "The second method is Eigenfaces, this method is base on PCA(principal components analysis), a technology that reduces the dimensionality of the pixel, maximizes all scatter from projected samples, so that the linear classifier is able to classify them. PCA helps find the orthonormal vector that best accounts the distribution of the face image in all database(Stolrasgky & Jakov 2015). However, the weakness of this method are all the scatter have been maximized includes the useful scatter that between-class. This means useful information for face recognition may be lost. Under varying lighting condition, the corresponding point will not be well clustered, resulting in classes mixed. The limitations that demonstrated from the experiment will further discuss in the next section. \n",
        "\n",
        "The third method is Linear Subspaces. This method uses 3 or more images from the same face but under different lighting, condition to build a 3-D basis for the linear subspace. According to the distance of selected new face to each linear subspace, choose the face with the closest distance. Although the linear subspaces method performs well under any lighting conditions. The face image that used require no any self-shadowing and does not perform well with varying facial expressions. Meanwhile, this method consumes high calculation time and large storage since it uses three or more images from the same face to build the 3-D basis. \n",
        "\n",
        "The last method is Fisherfaces. This method is base on FLD(Fisher’s Linear Discriminant). Same as Eigenfaces method, Fusherfaces reduce the dimensionality and still retain linear separability. FLD aims to make classification more reliable, maximizes the between-class scatter and minimizes the within-class scatter(Stolrasgky & Jakov 2015). FLD can handle the problem that commonly happened in projection to a smaller dimension might involve some loss of information(Thalles 2019). The experiments indicate Fisherfaces is the best method of the above-mentioned methods when dealing in lighting and expressions. \n",
        "\n",
        "To evaluating above-mentioned methods, three experiments have designed for testing their performance under different light condition, facial expression and the recognition of face wearing glasses. The light varied face and different facial expression photo are provided from Harvard Robotics Laboratory and Yale database.\n",
        "\n",
        "#Innovation\n",
        "\n",
        "The report is published on July 1997, Serval algorithms have been proposed for face recognition. However, evaluation or benchmarking studies that base on large databases(Chellappa et al. 1995)) is required at that time. The report contributes the comparison of four methods that adopting the face recognition, give the description of each method, evaluating their performance dealing different image condition. The result of experiments will be listed in the following.\n",
        "\n",
        "####1.The first experiment aims to test the variation in light, five subsets containing 5 people with the varying light condition were used in the experiment. This experiment is dived to two-part: extrapolation and interpolation. In extrapolation part, methods trined on subset 1 and tested from the samples from subsets 1,2,3. Subsequently, interpolation part was trined on subset 1 and 5 then tested on subsets 2,3,4. As shown in Figure 1 and 2 below. Four methods perform well in Subset 1 which the illumination is near frontal, in the subset 2 and subset 3, the error rate of Eigenface and Correlation methods has dramatically increased. By comparison, Linear Subspace and Fisherface methods keep steady error rate. Report point out Linear Subspace used three times information and computational time than Fisherface.\n",
        "\n",
        "<\\img src=\"https://github.com/Yujun-Liang/UTS_ML2019_ID12786277/blob/master/Figure%201.png\" width=\"300\"/>\n",
        "(Figure 1, Peter et al. 1997)\n",
        "<\\img src=\"https://github.com/Yujun-Liang/UTS_ML2019_ID12786277/blob/master/Figure%202.png\" width=\"300\"/>\n",
        "(Figure 2 Peter et al. 1997)\n",
        "\n",
        "####2.The second experiment is Variation in facial expression, eyewear, and lighting. A group of frontal face image includes 10 different human expression, 16 Group, 160 images in total are being tested. Figure 3 shows the error rate of four methods, Fisherface performs well in varying expression. In addition, the error rate of all methods is increased generally when the photo background is removed.\n",
        "<\\img src=\"https://github.com/Yujun-Liang/UTS_ML2019_ID12786277/blob/master/Figure%203.png\" width=\"300\"/> \n",
        "(Figure 3 Peter et al. 1997)\n",
        "\n",
        "####3.Glasses Recognition tests the performance between Eigenface and Fisherface, 36 face images are used in this experiment, half of them are wearing glasses. Results show the Fisherface have 5.3 percentage error rate while Eigenface has 52.6 percentage.\n",
        "\n",
        "#Technical quality\n",
        "\t\n",
        "3.The report has clearly explained four algorithms, detailed in the theory, transformation and how they work in face recognition Field. The reason why Fisherface method is the best method for handling is proved through theory and experiments result. Theory fully explained why FLD can handle the problem that commonly happened in projection to a smaller dimension might involve some loss of information. The experiments data is authoritative that from Harvard and Yale Face Database, the result shows plenty of evidence and presented through the figure.\n",
        "\n",
        "In the critical perspective. Incompleteness and lack of sample in the experiments are two main deficiencies. Firstly, Report point different pose may affect face recognition, the report has no attempt to deal with this problem. Secondly, occlusion is a serious problem in face recognition, which means the taken face in the image may partially hide behind a column or other object(Carrera. 2010), the report made an assumption that face has been located and aligned within the image, instead of developing further research of this problem. Finally, the sample of the first experiment is 330 images, 160 images used in the second experiment and 32 images used in the last experiment. The result drawn form the experiment is unconvincing, more simple is required.\n",
        "\n",
        "#Application and X-factor\n",
        "\n",
        "Face recognition can be applied in different domains, including video surveillance, human-machine interaction, photo cameras, video surveillance and law enforcement(Carrera.2010). According to my research, the proposed technique is rarely used in nowadays society, many problems in 20 years before is solved. For example, the different pose problem in above mentioned have solved by face landmark estimation that invented in 2014 by Vahid Kazenu and Josephine Sullivan(Kazemi &Sullivan 2014).\n",
        "\n",
        "In my option, this topic will be greatly discussed in the class, many technologies we used daily is about face recognition, includes face ID, image googling. The discussion may about the further development of the research work. For the well-known algorithms, the possibility of improving and extending. For example, adding procedures to PCA(Liu 2000), developing new kernel-based methods(Zhou & Tang 2009) or FLD into semi-supervised algorithms(Cai et al. 2007). Besides, we can talk about the ANN(Artificial neural network) wieldy used in face recognition nowadays, as known as deep learning that we are going to consider in the rest of the semester. The development of the computer allows us to make it practical because deep learning requires much more training data and computational power. \n",
        "\n",
        "#Presentation\n",
        "\n",
        "Overall, the report is structured and informative. In the introduction, the authors argue Fisherface is the best method handing varying light condition and facial expression. Each method that is going to compare is detailed describe in theory, transformation and how they work in face recognition field. Subsequently, the remaining section is all about supporting document. Therefore, experiments are designed for addressing the varying light condition and facial expression purpose expressly. Serval figures are used as evidence to prove the argument straightforwardly. The presentation style is easy to follow and understand.\n",
        "\n",
        "#References\n",
        "\n",
        "Chellappa, R. Wilson, C, L. Sirohey. 1995. ‘Human and Machine Recognition of Faces: A survey’ *Proceedings of the IEEE, vol*. 83. No 5.\n",
        "\n",
        "Carrera, P.F.D. 2010, *Face Recognition Algorithms*, Ion Marqu´es.\n",
        "\n",
        "D. Cai, X. He, and J. Han. 2007. ‘Semi-supervised discriminant analysis. Computer Vision’ *IEEE 11th International Conference on Computer Vision*, 14:1–7.\n",
        "\n",
        "D. Zhou and Z. Tang.2009. ‘Kernel-based improved discriminant analysis and its application to face recognition’ Soft Computing - *A Fusion of Foundations, Methodologies and Applications*, 14(2):103–111.\n",
        "\n",
        "F. Liu, Z. liang Wang, L. Wang, and X. yan Meng. 2005. ‘Aﬀective Computing and Intelligent Interaction’ *Facial Expression Recognition Using HLAC Features and WPCA*, pages 88–94. Springer Berlin / Heidelberg.\n",
        "\n",
        "Kazemi, V. Sullivan, J. 2014. *One Millisecond Face Alignment with an Ensemble of Regression Trees*, Computer Vision and Active Perception Lab, Sweden.\n",
        "\n",
        "Peter N. Belhumeur, Joao P. Hespanha, David J. Kriegman, 1997. ‘Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection’ *IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE*, Vol. 19, No. 7.\n",
        "\n",
        "Thalles. Jan 3, 2019. *An illustrative introduction to Fisher’s Linear Discriminant*. Viewed 26 August 2019. <https://sthalles.github.io/fisher-linear-discriminant/>\n",
        "\n",
        "Stolrasky, M,S. Jakov, N, B. April,2015. *Recognition Using Class Specific Linear Projection*. viewed 26 August 2019,\n",
        "<https://pdfs.semanticscholar.org/a0dd/76c11e17c276d933009c437c961917f56503.pdf>\n"
      ]
    }
  ]
}